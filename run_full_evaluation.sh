#!/bin/bash
# Agentless å®Œæ•´æµ‹è¯„æµç¨‹è„šæœ¬
# åŒ…å«ï¼šä¸‰çº§å®šä½ + ç»“æœè¯„ä¼°
#
# ä½¿ç”¨æ–¹æ³•ï¼š
#   1. ä¿®æ”¹è„šæœ¬é¡¶éƒ¨çš„"æ¨¡å‹é…ç½®"éƒ¨åˆ†ï¼Œè®¾ç½®æ¨¡å‹è·¯å¾„å’Œç›¸å…³å‚æ•°
#   2. ç¡®ä¿ vLLM æœåŠ¡å·²å¯åŠ¨ï¼ˆæˆ–ä½¿ç”¨è„šæœ¬æä¾›çš„å¯åŠ¨å‘½ä»¤ï¼‰
#   3. è¿è¡Œè„šæœ¬: ./run_full_evaluation.sh
#
# åˆ‡æ¢æ¨¡å‹ç¤ºä¾‹ï¼š
#   MODEL_PATH="/workspace/model/Qwen__Qwen3-32B/Qwen/Qwen3-32B"
#   MODEL_NAME="qwen3-32b"
#   MAX_MODEL_LEN=65536  # æ ¹æ®æ¨¡å‹è°ƒæ•´
#

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

# é¢œè‰²è¾“å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# ============================================================
# æ¨¡å‹é…ç½® - ä¿®æ”¹è¿™äº›å˜é‡å³å¯åˆ‡æ¢æ¨¡å‹
# ============================================================
# API æ¨¡å‹åç§°ï¼ˆAgentless è°ƒç”¨æ—¶ä½¿ç”¨ï¼Œéœ€è¦ä¸ vLLM çš„ --served-model-name ä¸€è‡´ï¼‰
MODEL_NAME="qwen3-32b"
# vLLM æœåŠ¡ç«¯å£
VLLM_PORT=8003
# vLLM æœåŠ¡åœ°å€ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
VLLM_URL="http://localhost:${VLLM_PORT}/v1"
# Agentless ä½¿ç”¨çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆé€šå¸¸ä¸ vLLM çš„ --max-model-len ä¸€è‡´ï¼‰
# æ³¨æ„ï¼šQwen3-32B çš„ max_position_embeddings=40960ï¼Œå»ºè®®ä½¿ç”¨ 32768 æˆ–æ›´å°
MAX_CONTEXT_LENGTH=32768          # æ ¹æ®æ¨¡å‹èƒ½åŠ›è°ƒæ•´ï¼Œæ¨¡å‹æœ€å¤§æ”¯æŒ 40960

# ============================================================
# å¸¸ç”¨æ¨¡å‹é…ç½®ç¤ºä¾‹ï¼ˆå–æ¶ˆæ³¨é‡Šå¹¶ä¿®æ”¹å³å¯ä½¿ç”¨ï¼‰
# ============================================================
# Qwen2.5-32B-Instruct (32K ä¸Šä¸‹æ–‡)
# MODEL_NAME="qwen2.5-32b"
# VLLM_PORT=8003
# MAX_CONTEXT_LENGTH=32768

# Qwen3-32B (64K ä¸Šä¸‹æ–‡)
# MODEL_NAME="qwen3-32b"
# VLLM_PORT=8003
# MAX_CONTEXT_LENGTH=65536

# å…¶ä»–æ¨¡å‹...
# MODEL_NAME="your-model-name"
# VLLM_PORT=8003
# MAX_CONTEXT_LENGTH=æ ¹æ®æ¨¡å‹è°ƒæ•´

# ============================================================
# å…¶ä»–é…ç½®
# ============================================================
DATASET_PATH="/workspace/locbench/data/Loc-Bench_V1_dataset.jsonl"
REPO_ROOT="/workspace/locbench/repos/locbench_repos"
OUTPUT_BASE="results/locbench"
NUM_THREADS=1

echo "=========================================="
echo "ğŸš€ Agentless å®Œæ•´æµ‹è¯„æµç¨‹"
echo "=========================================="
echo ""

# 1. æ£€æŸ¥ç¯å¢ƒ
echo "ğŸ“‹ æ­¥éª¤ 0: æ£€æŸ¥ç¯å¢ƒ..."
cd /workspace/locbench/Agentless

# æ£€æŸ¥ conda ç¯å¢ƒ
if ! conda env list | grep -q "agentless"; then
    echo -e "${RED}âŒ é”™è¯¯: æœªæ‰¾åˆ° agentless conda ç¯å¢ƒ${NC}"
    exit 1
fi

# æ¿€æ´»ç¯å¢ƒ
source /root/miniconda3/etc/profile.d/conda.sh
conda activate agentless
export PYTHONPATH=$PYTHONPATH:$(pwd)

# æ£€æŸ¥ vLLM æœåŠ¡
echo "ğŸ” æ£€æŸ¥ vLLM æœåŠ¡..."
echo "   æ¨¡å‹åç§°: $MODEL_NAME"
echo "   æœåŠ¡åœ°å€: $VLLM_URL"
if ! curl -s "${VLLM_URL}/models" > /dev/null 2>&1; then
    echo -e "${RED}âŒ é”™è¯¯: vLLM æœåŠ¡æœªè¿è¡Œï¼${NC}"
    echo "   è¯·å…ˆå¯åŠ¨ vLLM æœåŠ¡ï¼ˆç¡®ä¿æœåŠ¡åœ°å€ä¸º $VLLM_URLï¼‰"
    echo "   ç¡®ä¿ --served-model-name å‚æ•°è®¾ç½®ä¸º: $MODEL_NAME"
    exit 1
fi
echo -e "${GREEN}âœ… vLLM æœåŠ¡æ­£å¸¸è¿è¡Œ${NC}"

# æ£€æŸ¥æ•°æ®é›†å’Œä»“åº“
if [ ! -f "$DATASET_PATH" ]; then
    echo -e "${RED}âŒ é”™è¯¯: æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: $DATASET_PATH${NC}"
    exit 1
fi

if [ ! -d "$REPO_ROOT" ]; then
    echo -e "${RED}âŒ é”™è¯¯: ä»“åº“ç›®å½•ä¸å­˜åœ¨: $REPO_ROOT${NC}"
    exit 1
fi

echo -e "${GREEN}âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡${NC}"
echo ""

# 2. æ¸…ç†æ®‹ç•™çš„ worktreeï¼ˆé¿å…å†²çªï¼‰
echo "ğŸ§¹ æ¸…ç†æ®‹ç•™çš„ worktree..."
cd "$REPO_ROOT"
for repo in */; do
    cd "$repo" 2>/dev/null && git worktree prune 2>/dev/null || true
    cd .. 2>/dev/null
done
rm -rf /tmp/agentless_worktree_* 2>/dev/null || true
echo -e "${GREEN}âœ… æ¸…ç†å®Œæˆ${NC}"
echo ""

# 3. æ­¥éª¤ 1: æ–‡ä»¶çº§å®šä½
echo "=========================================="
echo "ğŸ“ æ­¥éª¤ 1: æ–‡ä»¶çº§å®šä½"
echo "=========================================="
cd /workspace/locbench/Agentless

python agentless/fl/localize.py \
    --file_level \
    --output_format locbench \
    --dataset_path "$DATASET_PATH" \
    --local_repo_root "$REPO_ROOT" \
    --output_folder "${OUTPUT_BASE}/file_level" \
    --model "$MODEL_NAME" \
    --backend openai \
    --max_context_length "$MAX_CONTEXT_LENGTH" \
    --num_threads "$NUM_THREADS" \
    --skip_existing

if [ ! -f "${OUTPUT_BASE}/file_level/loc_outputs.jsonl" ]; then
    echo -e "${RED}âŒ é”™è¯¯: æ­¥éª¤ 1 è¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆ${NC}"
    exit 1
fi

FILE_COUNT=$(wc -l < "${OUTPUT_BASE}/file_level/loc_outputs.jsonl")
echo -e "${GREEN}âœ… æ­¥éª¤ 1 å®Œæˆï¼å¤„ç†äº† $FILE_COUNT ä¸ªå®ä¾‹${NC}"
echo ""

# 4. æ­¥éª¤ 2: ç›¸å…³å…ƒç´ å®šä½
echo "=========================================="
echo "ğŸ”— æ­¥éª¤ 2: ç›¸å…³å…ƒç´ å®šä½"
echo "=========================================="

python agentless/fl/localize.py \
    --related_level \
    --output_format locbench \
    --dataset_path "$DATASET_PATH" \
    --local_repo_root "$REPO_ROOT" \
    --output_folder "${OUTPUT_BASE}/related_elements" \
    --model "$MODEL_NAME" \
    --backend openai \
    --max_context_length "$MAX_CONTEXT_LENGTH" \
    --top_n 3 \
    --compress_assign \
    --compress \
    --start_file "${OUTPUT_BASE}/file_level/loc_outputs.jsonl" \
    --num_threads "$NUM_THREADS" \
    --skip_existing

if [ ! -f "${OUTPUT_BASE}/related_elements/loc_outputs.jsonl" ]; then
    echo -e "${RED}âŒ é”™è¯¯: æ­¥éª¤ 2 è¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆ${NC}"
    exit 1
fi

RELATED_COUNT=$(wc -l < "${OUTPUT_BASE}/related_elements/loc_outputs.jsonl")
echo -e "${GREEN}âœ… æ­¥éª¤ 2 å®Œæˆï¼å¤„ç†äº† $RELATED_COUNT ä¸ªå®ä¾‹${NC}"
echo ""

# 5. æ­¥éª¤ 3: ç¼–è¾‘ä½ç½®å®šä½
echo "=========================================="
echo "ğŸ“ æ­¥éª¤ 3: ç¼–è¾‘ä½ç½®å®šä½"
echo "=========================================="

python agentless/fl/localize.py \
    --fine_grain_line_level \
    --output_format locbench \
    --dataset_path "$DATASET_PATH" \
    --local_repo_root "$REPO_ROOT" \
    --output_folder "${OUTPUT_BASE}/edit_location_samples" \
    --model "$MODEL_NAME" \
    --backend openai \
    --max_context_length "$MAX_CONTEXT_LENGTH" \
    --top_n 3 \
    --compress \
    --temperature 0.8 \
    --num_samples 4 \
    --start_file "${OUTPUT_BASE}/related_elements/loc_outputs.jsonl" \
    --num_threads "$NUM_THREADS" \
    --skip_existing

if [ ! -f "${OUTPUT_BASE}/edit_location_samples/loc_outputs.jsonl" ]; then
    echo -e "${RED}âŒ é”™è¯¯: æ­¥éª¤ 3 è¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆ${NC}"
    exit 1
fi

EDIT_COUNT=$(wc -l < "${OUTPUT_BASE}/edit_location_samples/loc_outputs.jsonl")
echo -e "${GREEN}âœ… æ­¥éª¤ 3 å®Œæˆï¼å¤„ç†äº† $EDIT_COUNT ä¸ªå®ä¾‹${NC}"
echo ""

# 6. è¯„ä¼°ç»“æœ
echo "=========================================="
echo "ğŸ“Š æ­¥éª¤ 4: è¯„ä¼°ç»“æœ"
echo "=========================================="

cd /workspace/locbench/Agentless

# åˆ›å»ºè¯„ä¼°è„šæœ¬ï¼ˆä½¿ç”¨ Agentless è‡ªå·±çš„è¯„ä¼°è„šæœ¬ï¼‰
cat > "${OUTPUT_BASE}/run_evaluation.py" << 'PYEOF'
import sys
import os

# æ·»åŠ è·¯å¾„
sys.path.insert(0, '/workspace/locbench/Agentless')
sys.path.insert(0, '/workspace/locbench/LocAgent')

# å°è¯•ä½¿ç”¨ Agentless çš„è¯„ä¼°è„šæœ¬
try:
    from evaluation.eval_metric import evaluate_results
    USE_AGENTLESS_EVAL = True
except ImportError:
    # å¦‚æœ Agentless çš„è¯„ä¼°è„šæœ¬ä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨ LocAgent çš„
    try:
        import sys
        sys.path.insert(0, '/workspace/locbench/LocAgent')
        from evaluation.eval_metric import evaluate_results
        USE_AGENTLESS_EVAL = False
    except ImportError:
        print("âŒ é”™è¯¯: æ‰¾ä¸åˆ°è¯„ä¼°è„šæœ¬")
        sys.exit(1)

import json
import pandas as pd

loc_file = sys.argv[1]
dataset_path = sys.argv[2]
output_file = sys.argv[3]

level2key_dict = {
    'file': 'found_files',
    'module': 'found_modules',
    'function': 'found_entities'
}

print(f"ğŸ“Š è¯„ä¼°æ–‡ä»¶: {loc_file}")
print(f"ğŸ“Š æ•°æ®é›†: {dataset_path}")

try:
    # ä½¿ç”¨ Loc-Bench æ•°æ®é›†
    results = evaluate_results(
        loc_file=loc_file,
        level2key_dict=level2key_dict,
        dataset='czlll/Loc-Bench_V1',
        split='test',
        dataset_path=dataset_path
    )
    
    # ä¿å­˜ç»“æœ
    if isinstance(results, pd.DataFrame):
        results_dict = results.to_dict('records')[0]
    else:
        results_dict = results

    # ç¡®ä¿æ‰€æœ‰ key éƒ½æ˜¯å­—ç¬¦ä¸²ï¼ˆå¤„ç†å¤šçº§åˆ—ç´¢å¼•äº§ç”Ÿçš„ tuple keyï¼‰
    # ä¾‹å¦‚ï¼š('file', 'acc@1') -> 'file.acc@1'
    def convert_keys_to_string(obj):
        if isinstance(obj, dict):
            new_dict = {}
            for k, v in obj.items():
                # å°† tuple key è½¬æ¢ä¸ºç‚¹å·åˆ†éš”çš„å­—ç¬¦ä¸²
                if isinstance(k, tuple):
                    new_key = '.'.join(str(x) for x in k)
                elif isinstance(k, (int, float, bool)) or k is None:
                    new_key = str(k)
                else:
                    new_key = k
                new_dict[new_key] = convert_keys_to_string(v)
            return new_dict
        elif isinstance(obj, list):
            return [convert_keys_to_string(item) for item in obj]
        else:
            return obj

    results_dict = convert_keys_to_string(results_dict)

    with open(output_file, 'w') as f:
        json.dump(results_dict, f, indent=2, ensure_ascii=False)
    
    print("\nğŸ“Š è¯„ä¼°ç»“æœ:")
    if isinstance(results, pd.DataFrame):
        print(results.to_string())
    else:
        print(json.dumps(results_dict, indent=2, ensure_ascii=False))
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
except Exception as e:
    print(f"âŒ è¯„ä¼°å‡ºé”™: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)
PYEOF

# è¿è¡Œè¯„ä¼°
if [ -f "/workspace/locbench/LocAgent/evaluation/eval_metric.py" ]; then
    # æ¿€æ´» LocAgent ç¯å¢ƒï¼ˆå¦‚æœéœ€è¦ï¼‰
    if conda env list | grep -q "locagent"; then
        conda activate locagent
    fi
    
    python "${OUTPUT_BASE}/run_evaluation.py" \
        "${OUTPUT_BASE}/edit_location_samples/loc_outputs.jsonl" \
        "$DATASET_PATH" \
        "${OUTPUT_BASE}/evaluation_results.json"
    
    if [ -f "${OUTPUT_BASE}/evaluation_results.json" ]; then
        echo ""
        echo "ğŸ“ˆ è¯„ä¼°ç»“æœæ‘˜è¦:"
        python -c "
import json
try:
    with open('${OUTPUT_BASE}/evaluation_results.json', 'r') as f:
        data = json.load(f)
        for key, value in data.items():
            if isinstance(value, dict):
                print(f\"{key}:\")
                for k, v in value.items():
                    print(f\"  {k}: {v}\")
            else:
                print(f\"{key}: {value}\")
except Exception as e:
    print(f'è¯»å–ç»“æœæ—¶å‡ºé”™: {e}')
" 2>/dev/null || cat "${OUTPUT_BASE}/evaluation_results.json"
    fi
else
    echo -e "${YELLOW}âš ï¸  è­¦å‘Š: LocAgent è¯„ä¼°è„šæœ¬ä¸å­˜åœ¨ï¼Œè·³è¿‡è¯„ä¼°${NC}"
    echo "   ä½ å¯ä»¥æ‰‹åŠ¨è¿è¡Œè¯„ä¼°ï¼š"
    echo "   cd /workspace/locbench/LocAgent"
    echo "   python evaluation/eval_metric.py ..."
fi

echo ""
echo "=========================================="
echo -e "${GREEN}ğŸ‰ å®Œæ•´æµ‹è¯„æµç¨‹å®Œæˆï¼${NC}"
echo "=========================================="
echo ""
echo "ğŸ“ ç»“æœæ–‡ä»¶ä½ç½®:"
echo "   - æ–‡ä»¶çº§å®šä½: ${OUTPUT_BASE}/file_level/loc_outputs.jsonl"
echo "   - ç›¸å…³å…ƒç´ å®šä½: ${OUTPUT_BASE}/related_elements/loc_outputs.jsonl"
echo "   - ç¼–è¾‘ä½ç½®å®šä½: ${OUTPUT_BASE}/edit_location_samples/loc_outputs.jsonl"
echo "   - è¯„ä¼°ç»“æœ: ${OUTPUT_BASE}/evaluation_results.json"
echo ""
echo "ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:"
echo "   - æ–‡ä»¶çº§: $FILE_COUNT ä¸ªå®ä¾‹"
echo "   - ç›¸å…³å…ƒç´ : $RELATED_COUNT ä¸ªå®ä¾‹"
echo "   - ç¼–è¾‘ä½ç½®: $EDIT_COUNT ä¸ªå®ä¾‹"
echo ""
